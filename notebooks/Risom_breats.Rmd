---
title: "Risom_breast_analysis"
author: "Chiara Schiller"
date: "2023-05-04"
output: html_document
---

##Summary
In this scipt, I explore the Risom breast dataset from https://data.mendeley.com/datasets/d87vg86zd8/3. I test if I can also compare SCNA tools with true biological data, as ground-truth is missing
The dataset has progressor and non-progressor sampples of DCIS. I checked the cell type abundance differences and they are okay.
I run giotto on it and try to find statistically different cell-cell interactions between progressors and non-progressors.
The cohorts are imbalanced and I sample them up. However, the results do not look very promising.

##Script

Load packages
```{r}
library(Giotto)
library(reticulate)
library(readr)
library(tidyverse)
library(DESeq2)
library(ggplot2)
library(ggfortify)
library(factoextra)
```

Load in data
```{r}
data = read_csv("./../../../../data/Risom_breast/Single_Cell_Data.csv")
unique(data$celllineage) # --> is less defined than phenotype
unique(data$compartment)
```
###Cell type distributions
```{r}
table(data$Point_Num ,data$phenotype)
```

# exclude normal and look at ct distribution between progressor and non-progressor

```{r}
meta = read_csv("./../../../../data/Risom_breast/Table_S1_Patient_Feature_Table.csv")
meta = meta %>% rename("Point_Num" = "PointNumber")
data = left_join(data, meta, by = "Point_Num")


prop = as.data.frame.matrix(prop.table(table(data$Patient_ID, data$phenotype),1))
prop$Patient_ID = as.numeric(rownames(prop))
prop = left_join(prop, meta[,c("Patient_ID", "Status")], by = "Patient_ID")

prop = prop %>% filter(Status %in% c("progressor", "nonprogressor"))

```
first, look at ct distributino between progressors and non-progressors
```{r, fig.width=12}
# Melt data into long format
melted_df <- gather(prop, key = "cell_type", value = "percentage", -c("Patient_ID", "Status"))

# Create stacked barplot
melted_df$Patient_ID = as.character(melted_df$Patient_ID)

#pdf("./../../output/breast_risom_ct_abundances.pdf", height = 4, width = 6)
ggplot(melted_df, aes(x = factor(cell_type), y = percentage, color = Status, group = interaction(Status, cell_type))) +
  geom_boxplot() +
  #facet_grid(. ~ tool) +
  xlab("cell type") +
  ylab("abundance") +
  theme_test() +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1))
#dev.off()
```
No bigger cell type differences, maybe a bit more tumor cells? Let's compare only bigger categories

```{r}
#compartment enrichment per cell type
prop = as.data.frame.matrix(prop.table(table(data$Patient_ID, data$celllineage),1))
prop$Patient_ID = as.numeric(rownames(prop))
prop = left_join(prop, meta[,c("Patient_ID", "Status")], by = "Patient_ID")

prop = prop %>% filter(Status %in% c("progressor", "nonprogressor"))

# Melt data into long format
melted_df <- gather(prop, key = "cell_type", value = "percentage", -c("Patient_ID", "Status"))

# Create stacked barplot
melted_df$Patient_ID = as.character(melted_df$Patient_ID)

#pdf("./../../output/breast_risom_rough_ct_abundances.pdf", height = 3, width = 4)
ggplot(melted_df, aes(x = factor(cell_type), y = percentage, color = Status, group = interaction(Status, cell_type))) +
  geom_boxplot() +
  #facet_grid(. ~ celllineage) +
  xlab("cell type") +
  ylab("abundance") +
  theme_test() +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1))
#dev.off()
```
## Giotto analysis

Get x and y coordinates of label or event
```{r}
library(purrr)

# Set directory where CSV files are located
csv_dir <- "./../../../../data/Risom_breast/Segmetation_Outlines_and_Labels_Mendeley/"

# Get file names of all CSV files in directory
csv_files <- list.files(csv_dir, pattern = "\\.csv$", full.names = TRUE)
names <- list.files(csv_dir, pattern = "\\.csv$", full.names = FALSE)
names = sub(".csv", "", names)

# Read in all CSV files and store in a list
csv_list <- map(csv_files, read.csv)
names(csv_list) = names

for (i in seq_along(csv_list)) {
  csv_list[[i]]$Point_Num <- as.numeric(rep(names(csv_list)[i], nrow(csv_list[[i]])))
}
```

Join metadata with real data
```{r}
#data_df <- do.call(rbind, csv_list)
#data = left_join(data, data_df, by = c("label", "Point_Num"))
meta = read_csv("./../../../../data/Risom_breast/Table_S1_Patient_Feature_Table.csv")
meta = meta %>% rename("Point_Num" = "PointNumber")

DCIS_pat = meta %>% 
  filter(LDA_Type == "DCIS")

DCIS_pat = DCIS_pat$Point_Num

# or rather join big datasets to list
pheno = data %>% 
  filter(Point_Num %in% DCIS_pat) %>%
  select(Point_Num, celllineage, label) # or phenotype instead of celllineage

join_df <- function(df) {
  left_join(df, pheno, by = c("label", "Point_Num"))
}

colname_set <- function(df) {
  colnames(df) = c("cell_ID", "x", "y", "sample", "ct")
}

# Apply the join_df function to each element of the list using lapply
list_joined <- lapply(csv_list, join_df)

for (i in 1:length(list_joined)){
  colnames(list_joined[[i]]) = c("cell_ID", "x", "y", "sample", "ct")
  list_joined[[i]] = list_joined[[i]] %>% 
    filter(Point_Num %in% DCIS_pat) #%>%
    #select(Point_Num, celllineage, label)
}

```

Run Giotto
```{r}
#Giotto usage for simulated data as input

library(Giotto)
library(reticulate)
library(readr)
library(tidyverse)

# Giotto and python configurations
# Create Giotto path
my_instructions = createGiottoInstructions(python_path = '/Users/chiaraschiller/Library/r-miniconda-arm64/bin/python3')
Sys.setenv(RETICULATE_PYTHON = "/Users/chiaraschiller/Library/r-miniconda-arm64/bin/python3") 
#py_config()

data_list = list_joined
giotto_list = list()

x=0
# create dataframe with random values to pretend to have expression data to generate a giotto object
for (i in data_list){
  x = x+1
  df = data.frame(cbind(rep(1,nrow(i)), rep(1,nrow(i))))
  #df <- data.frame(matrix(runif(nrow(data_list[[i]]) * 2), nrow = nrow(data_list[[i]])))
  df$cell_ID = i$cell_ID
  colnames(df) = c("M1", "M2", "cell_ID")

  metadata = cbind(as.character(i$ct), as.character(df$cell_ID))
  colnames(metadata) = c("ct", "cell_ID")
  # colbind the two datasets
  #data = cbind(df, as.data.frame(data))
  data = createGiottoObject(raw_exprs = as.data.frame(t(df)),
                          spatial_locs = as.data.frame(i[, !(names(i) %in% c("ct"))]),
                          #instructions = my_instructions,
                          cell_metadata = metadata)

  data <- normalizeGiotto(gobject = data)
  # create network (required for binSpect methods)
  giotto_list[[names[x]]] = createSpatialNetwork(gobject = data, minimum_k = 2,
                                                  #method = "Delaunay",
                                                  method = "kNN",
                                                  k = 10,
                                                  )
}

# calculate cell proximities
# PI value is the proximity index of the feature in the cluster
cell_PI=list()
x=0

for (i in giotto_list){
  x=x+1
  cell_proximities = cellProximityEnrichment(gobject = i,
                        cluster_column = 'ct',
                        #spatial_network_name = 'Delaunay_network',
                        spatial_network_name = 'kNN_network',
                        adjust_method = 'fdr',
                        number_of_simulations = 1000)

  cell_PI[[names[x]]] = separate(cell_proximities[[2]], unified_int, into = c("label1", "label2"), sep = "--")
  #names(cell_PI)[i]=gsub("\\..*", "", files[i])
  #write.csv(cell_PI[[files[x]]],file=paste0("./../../output/sim_100_01pref",gsub("\\..*", "", files[x]) ,"_proximities.csv"),row.names = TRUE)
}

## create matrix for comparison
#data = cell_PI[[1]]
data = do.call("rbind", cell_PI)

data$sample <- sub(".[0-9]*$", "", rownames(data))

data = data %>% select(label1, label2, PI_value, sample)

data$key = paste(data$label1, data$label2, sep = "_")
data = data %>% select(-c(label1, label2))


data = spread(data, key = key, value = PI_value)
rownames(data) = data$sample
data = data[,-1]
write.csv(data,"./../../../Comparison/results_4ct_self/Giotto_kNN10_4ct_self.csv")

data[is.na(data)] <- 0

```
Look at heatmap of interactions

```{r, fig.width=30, fig.height=7}

library(pheatmap)
pheatmap(back)
```
## Look for cell-cell interactions differences between the groups

Data wrangling
```{r, fig.width=30, fig.height=7}
# match patient information to have progressors and non progressors
meta = read_csv("./../../../../data/Risom_breast/Table_S1_Patient_Feature_Table.csv")
meta = meta %>% rename("Point_Num" = "PointNumber")

dat$Point_Num = as.numeric(rownames(dat))
dat = left_join(dat, meta[,c("Patient_ID", "Status", "Point_Num")], by = "Point_Num")

# generate table for progressor and non-progressor
dat_progr = dat %>% filter(Status == "progressor")
dat_nonprogr = dat %>% filter(Status == "nonprogressor")

pheatmap(as.matrix(dat_progr[ , !names(dat_progr) %in% c("Patient_ID", "Status", "Point_Num")], na.rm = TRUE), cluster_rows = FALSE, cluster_cols = FALSE)
```

Look at enriched interactions for progressors
```{r, fig.width=30, fig.height=7}

sort(colMeans(dat_progr[ , !names(dat_progr) %in% c("Patient_ID", "Status", "Point_Num")], na.rm = TRUE), decreasing = TRUE)
```
And at enriched interactions of non-progressors
```{r, fig.width=30, fig.height=7}
pheatmap(as.matrix(dat_nonprogr[ , !names(dat_nonprogr) %in% c("Patient_ID", "Status", "Point_Num")]), cluster_rows = FALSE, cluster_cols = FALSE)
sort(colMeans(dat_nonprogr[ , !names(dat_nonprogr) %in% c("Patient_ID", "Status", "Point_Num")], na.rm = TRUE), decreasing = TRUE)
```
Make DESeq analysis

```{r}
# only include interactions present in both groups
# Load the DESeq2 package
intersect(colnames(dat_nonprogr), colnames(dat_progr))
# Load count data (replace 'counts.csv' with the name of your file)
counts <- read.csv("counts.csv", row.names = 1)

# Create a DESeq2 object
dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = metadata,
                              design = ~ group)

# Perform differential expression analysis
dds <- DESeq(dds)
# Extract the results
results <- results(dds)

# Print the top differentially expressed genes (replace 'log2FC' with the name of the log2 fold change column)
topGenes <- head(results[order(results$log2FoldChange, decreasing = TRUE), ], n = 10)
print(topGenes)
```

## look at PCA if cohorts can be distinguished from each other

```{r}
dat = dat %>% filter(Status %in% c("progressor", "nonprogressor"))
df = dat[ , !names(dat_nonprogr) %in% c("Patient_ID", "Status", "Point_Num")]
df[is.na(df)] <- 0
# some datasets have zero variance column (sigval in histocat). They cannot be scaled
pca_res <- prcomp(df, scale. = TRUE)

df$group = dat$Status

print(autoplot(pca_res, data = df, colour = 'group') +
      ggtitle(names(all)[i]) +
        theme_bw()
      )
```

Cohorts cannot be distinguished based on cell-cell interactions here in PCA

Run random forest to look at importances

```{r}
stat = list()
# Load required packages
library(caret)
library(randomForest)
# Create an index variable for the two groups
group_index <- as.factor(df$group)

# write F1 and FDR function
# Calculate the F1 score
F1_Score <- function(predictions, actual) {
  res = unique(actual)
  TP <- sum(predictions == res[1] & actual == res[1])
  FP <- sum(predictions == res[1] & actual == res[2])
  FN <- sum(predictions == res[2] & actual == res[1])
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2 * precision * recall / (precision + recall)
  FDR <- FP / (TP + FP)
  return(c(F1, FDR))
}

# Set seed for reproducibility
set.seed(123)
```

Run only once
```{r}

# Combine index variable with data
data <- df

# Split data into training and test sets
trainIndex <- createDataPartition(df$group, p = 0.7, list = FALSE, times = 1)
train <- data[trainIndex, ]
test <- data[-trainIndex, ]

# Define the model
model <- caret::train(group ~ ., data = train, method = "rf", trControl = trainControl(method = "cv", number = 5)) # in formular, just column name should be named (here group)

# Make predictions on the test set
predictions <- predict(model, newdata = test)


stat <- F1_Score(as.character(predictions), test$group)

# View the F1 score

```
Check for error:
```{r}
# Check for missing values
sum(is.na(train))

# Identify rows with complete cases
complete_cases <- complete.cases(train)

# Remove rows with missing values
train <- na.omit(train[complete_cases,])

# Train the random forest model
library(caret)
train(group_index ~ ., data = train, method = "rf", trControl = trainControl(method = "cv", number = 5))
str(train)
```
##Imbalanced data

how to deal with imbalanced dataset? Here I sample up
```{r}
trainup<-upSample(x=train[,-ncol(train)],
                  y=as.factor(train$group))

# look at upsamples data in PCA

d = trainup[ , !names(trainup) %in% c("Class")]
d[is.na(d)] <- 0
# some datasets have zero variance column (sigval in histocat). They cannot be scaled
pca_res <- prcomp(d, scale. = TRUE)

d$group = trainup$Class

print(autoplot(pca_res, data = d, colour = 'group') +
      #ggtitle(names(all)[i]) +
        theme_bw()
      )

```
Run PCA with upsamples data
```{r}
stat = list()
# Load required packages
library(caret)
library(randomForest)
# Create an index variable for the two groups
group_index <- as.factor(trainup$Class)

# write F1 and FDR function
# Calculate the F1 score
F1_Score <- function(predictions, actual) {
  res = unique(actual)
  TP <- sum(predictions == res[1] & actual == res[1])
  FP <- sum(predictions == res[1] & actual == res[2])
  FN <- sum(predictions == res[2] & actual == res[1])
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2 * precision * recall / (precision + recall)
  FDR <- FP / (TP + FP)
  return(c(F1, FDR))
}

# Set seed for reproducibility
set.seed(123)
```

Run only once
```{r}

# Combine index variable with data
data <- trainup

# Split data into training and test sets
trainIndex <- createDataPartition(data$Class, p = 0.7, list = FALSE, times = 1)
train <- data[trainIndex, ]
test <- data[-trainIndex, ]

# Define the model
model <- caret::train(Class ~ ., data = train, method = "rf", trControl = trainControl(method = "cv", number = 5)) # in formular, just column name should be named (here group)

# Make predictions on the test set
predictions <- predict(model, newdata = test)


stat <- F1_Score(as.character(predictions), test$Class)


# View the F1 score

```

Train k-fold cv 10 times with balanced dataset

```{r}
target <- "group"


balance_data <- function(data, target) {
  # Identify minority and majority class
  table_data <- table(data[[target]])
  minority_class <- names(table_data)[which.min(table_data)]
  majority_class <- names(table_data)[which.max(table_data)]
  
  # Get 10 of 14 samples from minority class
  minority_data <- data[data[[target]] == minority_class, ]
  minority_data_balanced <- minority_data[1:10, ]
  minority_data_test <- minority_data[-(1:10), ]
  
  # Get all samples from majority class
  majority_data <- data[data[[target]] == majority_class, ]
  majority_train = majority_data[sample(nrow(majority_data), 10), ]
  # down-sample data
  sampled_rows <- majority_data[!rownames(majority_data) %in% rownames(majority_train), ]
  majority_data <- sampled_rows[sample(nrow(sampled_rows), 4), ]
  test = rbind(minority_data_test, majority_data)
  
  # Combine balanced data and return
  balanced_data <- rbind(minority_data_balanced, majority_train)
  return(list(balanced_data = balanced_data, test_data = test))
}


# Balance data and get test data
data_balanced <- balance_data(data, target)$balanced_data
data_test <- balance_data(data, target)$test_data

# Create 10-folds for cross-validation on balanced data
#folds = 
#folds <- ?createFolds(data_balanced[[target]], k = 10, list = TRUE, returnTrain = TRUE)

# Create a list to store the models
models <- list()
accuracies = list()

# Loop through each fold and train a random forest model on balanced data
for (i in 1:10) {
  # Get the training and test sets for this fold
  train_data <- balance_data(data, target)$balanced_data
  test_data <- data_test
  
  # Train the random forest model on the balanced data
  rf_model <- caret::train(group ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv", number = 5)) # in formular, just column name should be named (here group)
  
  # Store the model in the list
  models[[i]] <- rf_model
  
  # Use the predict function to make predictions on the test data for each model
  predictions <- predict(rf_model, newdata = test_data)
  accuracies[[i]] = confusionMatrix(as.factor(predictions), as.factor(test_data$group))$overall["Accuracy"]

}

# Calculate the accuracy of each model on the test data
accuracies <- sapply(predictions, function(preds) {
  confusionMatrix(preds, test_data[[target]])$overall["Accuracy"]
})

# Calculate the average accuracy of the ensemble
ensemble_accuracy <- mean(unlist(accuracies))

```

The performed analysis shows the difficulty when using biological data


```{r}
sessionInfo()
```
























